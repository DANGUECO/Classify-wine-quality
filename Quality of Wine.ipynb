{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this assignment is file **whitewine.csv** which is provided with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was adapted from the Wine Quality Dataset (https://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "For more information, read [Cortez et al., 2009: http://dx.doi.org/10.1016/j.dss.2009.05.016].\n",
    "\n",
    "Input variables (based on physicochemical tests):\n",
    "\n",
    "    1 - fixed acidity \n",
    "    2 - volatile acidity \n",
    "    3 - citric acid \n",
    "    4 - residual sugar \n",
    "    5 - chlorides \n",
    "    6 - free sulfur dioxide \n",
    "    7 - total sulfur dioxide \n",
    "    8 - density \n",
    "    9 - pH \n",
    "    10 - sulphates \n",
    "    11 - alcohol \n",
    "Output variable (based on sensory data):\n",
    "\n",
    "    12 - quality (0: normal wine, 1: good wine)\n",
    "    \n",
    "## Problem statement\n",
    "Predict the quality of a wine given its input variables. Use AUC (area under the receiver operating characteristic curve) as the evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load and explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        0  \n",
       "1      9.5        0  \n",
       "2     10.1        0  \n",
       "3      9.9        0  \n",
       "4      9.9        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/OEM/Desktop/DATA201/A4/whitewine.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4715 entries, 0 to 4714\n",
      "Data columns (total 12 columns):\n",
      "fixed_acidity           4715 non-null float64\n",
      "volatile_acidity        4715 non-null float64\n",
      "citric_acid             4715 non-null float64\n",
      "residual_sugar          4715 non-null float64\n",
      "chlorides               4715 non-null float64\n",
      "free_sulfur_dioxide     4715 non-null float64\n",
      "total_sulfur_dioxide    4715 non-null float64\n",
      "density                 4715 non-null float64\n",
      "pH                      4715 non-null float64\n",
      "sulphates               4715 non-null float64\n",
      "alcohol                 4715 non-null float64\n",
      "quality                 4715 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 442.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3655\n",
       "1    1060\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"quality\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that this dataset is unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions and Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[1]. Split the given data using stratify sampling into 2 subsets: training (80%) and test (20%) sets. Use random_state = 42. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3772  Training Set + 943  Testing Set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, train_size=0.8, test_size=0.2, random_state = 42)\n",
    "print(len(train_set), ' Training Set +', len(test_set), ' Testing Set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[2]. Use ``GridSearchCV`` and ``Pipeline`` to tune hyper-parameters for 3 different classifiers including ``KNeighborsClassifier``, ``LogisticRegression`` and ``svm.SVC`` and report the corresponding AUC values on the training and test sets. Note that a scaler may need to be inserted into each pipeline.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You may want to use `kernel='rbf'` and tune `C` and `gamma` for `svm.SVC`. Find out how to enable probability estimates (for Question 3).\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform hyper parameter optimization\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "#Same for train set(Target is purchase)\n",
    "X_train = train_set.drop(\"quality\", axis=1) # drop labels for training set\n",
    "y_train = train_set[\"quality\"].copy()\n",
    "\n",
    "#same for test set\n",
    "X_test = test_set.drop(\"quality\", axis=1)\n",
    "y_test = test_set[\"quality\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----AUC Values from KNN train and test Set----\n",
      "test accuracy:  0.741996991104134\n",
      "train test accuracy:  0.9001573654254292\n",
      "Best parameters:  {'knn__leaf_size': 10, 'knn__n_neighbors': 5}\n",
      "KNN AUC value from test set:  0.6303113553113554\n",
      "KNN AUC value from train set:  0.7413306321949964\n"
     ]
    }
   ],
   "source": [
    "#------KNeighborsClassifier-----\n",
    "pipelineone = Pipeline([('knn', KNeighborsClassifier())])\n",
    "param_grid = {'knn__n_neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "              'knn__leaf_size': [10,20,30,40,50,60,70,80,90,100]\n",
    "             }\n",
    "\n",
    "#Gridsearch takes in param_grid, and pipeline.\n",
    "gridone = GridSearchCV(pipelineone, param_grid, cv =5, scoring = 'roc_auc')\n",
    "gridone.fit(X_train, y_train)\n",
    "\n",
    "testscore = gridone.score(X_test, y_test)\n",
    "trainscore = gridone.score(X_train, y_train)\n",
    "print('----AUC Values from KNN train and test Set----')\n",
    "print('test accuracy: ', testscore)\n",
    "print('train test accuracy: ', trainscore)\n",
    "\n",
    "\n",
    "#on the testing data\n",
    "y_testpred = gridone.predict(X_test)\n",
    "\n",
    "#on the training data\n",
    "y_trainpred = gridone.predict(X_train)\n",
    "\n",
    "# summarize and present ROC score\n",
    "#roc takes in y_true and y_score\n",
    "KNNAUCtest = roc_auc_score(y_test, y_testpred)\n",
    "KNNAUCtrain = roc_auc_score(y_train, y_trainpred)\n",
    "print('Best parameters: ', gridone.best_params_)\n",
    "print('KNN AUC value from test set: ', (KNNAUCtest))\n",
    "print('KNN AUC value from train set: ', (KNNAUCtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----AUC Values from Logistic Regression train and test Set----\n",
      "test accuracy:  0.7849228152799582\n",
      "train test accuracy:  0.778837063476751\n",
      "Best parameters:  {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'logisticregression__solver': 'liblinear'}\n",
      "Logistic Regress AUC value from test set:  0.6040031397174254\n",
      "Logistic Regress AUC value from train set:  0.6089740497781208\n"
     ]
    }
   ],
   "source": [
    "#-------LogisticRegression-----\n",
    "#[0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "pipelinetwo = Pipeline([('logisticregression', LogisticRegression())])\n",
    "param_grid = {'logisticregression__penalty' : ['l2'],\n",
    "              'logisticregression__C' : [10],\n",
    "              'logisticregression__solver' : ['liblinear']}\n",
    "#Gridsearch takes in param_grid, and pipeline.\n",
    "gridtwo = GridSearchCV(pipelinetwo, param_grid, cv =5, scoring = 'roc_auc')\n",
    "gridtwo.fit(X_train, y_train)\n",
    "\n",
    "testscore = gridtwo.score(X_test, y_test)\n",
    "trainscore = gridtwo.score(X_train, y_train)\n",
    "print('----AUC Values from Logistic Regression train and test Set----')\n",
    "print('test accuracy: ', testscore)\n",
    "print('train test accuracy: ', trainscore)\n",
    "\n",
    "\n",
    "#on the testing data\n",
    "y_testpred = gridtwo.predict(X_test)\n",
    "\n",
    "#on the training data\n",
    "y_trainpred = gridtwo.predict(X_train)\n",
    "\n",
    "# summarize and present ROC score\n",
    "#roc takes in y_true and y_score\n",
    "logAUCtest = roc_auc_score(y_test, y_testpred)\n",
    "logAUCtrain = roc_auc_score(y_train, y_trainpred)\n",
    "print('Best parameters: ', gridtwo.best_params_)\n",
    "print('Logistic Regress AUC value from test set: ', (logAUCtest))\n",
    "print('Logistic Regress AUC value from train set: ', (logAUCtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----AUC Values from SVM train and test Set----\n",
      "test accuracy:  0.8040293040293041\n",
      "train test accuracy:  1.0\n",
      "Best parameters:  {'svc__C': 1, 'svc__gamma': 1}\n",
      "SVC AUC value from test set:  0.6596971480900052\n",
      "SVC AUC value from train set:  0.9953051643192488\n"
     ]
    }
   ],
   "source": [
    "#-----------svm.SVC------------\n",
    "pipelinethree = Pipeline([('svc', SVC(kernel='rbf', probability = True))])\n",
    "\n",
    "param_grid = {\n",
    "        'svc__C': [1],\n",
    "        'svc__gamma': [1]}\n",
    "\n",
    "#Gridsearch takes in param_grid, and pipeline.\n",
    "gridthree = GridSearchCV(pipelinethree, param_grid, cv =5, scoring = 'roc_auc')\n",
    "gridthree.fit(X_train, y_train)\n",
    "\n",
    "testscore = gridthree.score(X_test, y_test)\n",
    "trainscore = gridthree.score(X_train, y_train)\n",
    "print('----AUC Values from SVM train and test Set----')\n",
    "print('test accuracy: ', testscore)\n",
    "print('train test accuracy: ', trainscore)\n",
    "\n",
    "#on the testing data\n",
    "y_testpred = gridthree.predict(X_test)\n",
    "\n",
    "#on the training data\n",
    "y_trainpred = gridthree.predict(X_train)\n",
    "\n",
    "# summarize and present ROC score\n",
    "#roc takes in y_true and y_score\n",
    "SVMAUCtest = roc_auc_score(y_test, y_testpred)\n",
    "SVMAUCtrain = roc_auc_score(y_train, y_trainpred)\n",
    "print('Best parameters: ', gridthree.best_params_)\n",
    "print('SVC AUC value from test set: ', (SVMAUCtest))\n",
    "print('SVC AUC value from train set: ', (SVMAUCtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[3]. Train a soft ``VotingClassifier`` with the estimators are the three tuned pipelines obtained from [2]. Report the AUC values on the training and test sets. Comment on the performance of the ensemble model.**\n",
    "\n",
    "Hint: consider the voting method.\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test score with softvote:  0.8686420722135008\n",
      "AUC train score with softvote:  0.9997909833429802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Voting Classifier with soft voting \n",
    "\n",
    "estim = [('knn', gridone), ('lr', gridtwo),('svc', gridthree)]\n",
    "\n",
    "softvote = VotingClassifier(estimators = estim, voting ='soft') \n",
    "softvote.fit(X_train, y_train) \n",
    "\n",
    "#on the testing data\n",
    "y_testproba = softvote.predict_proba(X_test)\n",
    "#on the training data\n",
    "y_trainproba = softvote.predict_proba(X_train)\n",
    "\n",
    "#ROC\n",
    "print('AUC test score with softvote: ', roc_auc_score(y_test,y_testproba[:, 1]))\n",
    "print('AUC train score with softvote: ', roc_auc_score(y_train,y_trainproba[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT ON PERFORMANCE OF THE ENSEMBLE MODEL:\n",
    "\n",
    "Predictions for the training set improved drastically. The ensemble model has a training AUC value that is pretty much correct 100% and is outstanding. The AUC values for test score have improved overtime with a model that is 86.9% correct. The voting classifier helped improve the test score overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[4]. Redo [3] with a sensible set of ``weights`` for the estimators. Comment on the performance of the ensemble model in this case. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOFT AUC value from test set(With Weights):  0.8040293040293041\n",
      "SOFT AUC value from train set(With Weights):  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Voting Classifier with soft voting \n",
    "estim = [('knn', gridone), ('lr', gridtwo),('svc', gridthree)]\n",
    "\n",
    "#Sensible set of weights:\n",
    "#KNN = 0\n",
    "#LR = 0\n",
    "#SVC = 1 \n",
    "softvote = VotingClassifier(estimators = estim, voting ='soft',  weights = [0,0,1] ) \n",
    "softvote.fit(X_train, y_train) \n",
    "\n",
    "#on the testing data\n",
    "y_testpred = softvote.predict_proba(X_test)\n",
    "#on the training data\n",
    "y_trainpred = softvote.predict_proba(X_train)\n",
    "\n",
    "# summarize and present ROC score\n",
    "#roc takes in y_true and y_score\n",
    "VotingAUCtest = roc_auc_score(y_test, y_testpred[:,1])\n",
    "VotingAUCtrain = roc_auc_score(y_train, y_trainpred[:,1])\n",
    "print('SOFT AUC value from test set(With Weights): ', (VotingAUCtest))\n",
    "print('SOFT AUC value from train set(With Weights): ', (VotingAUCtrain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT ON THE PERFORMANCE OF THE ENSEMBLE MODEL:\n",
    "\n",
    "It does not really improve. When you add weights, you are looping and checking which is the best combination by weighting the occurrences of the predicted labels. This can somtimes improve the model although, at a cost of longer time. The prev result already has a training set that was 100%, but the test set ended up downgrading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[5]. Use the ``VotingClassifier`` with ``GridSearchCV`` to tune the hyper-parameters of the individual estimators. The parameter grid should be a combination of those in [2]. Report the AUC values on the training and test sets. Comment on the performance of the ensemble model. **\n",
    "\n",
    "Note that it may take a long time to run your code for this question.\n",
    "\n",
    "Document: https://scikit-learn.org/stable/modules/ensemble.html#using-the-votingclassifier-with-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine AUC value from test set:  0.8686355311355312\n",
      "Combine AUC value from train set:  0.999780934465239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "classifier1 = KNeighborsClassifier()\n",
    "classifier2 = LogisticRegression()\n",
    "classifier3 = SVC(kernel='rbf', probability = True)\n",
    "\n",
    "#combine to make a voting pipeline\n",
    "voteclassifier = VotingClassifier(estimators = [('knn', classifier1), ('logisticregression', classifier2),\n",
    "                                                ('svc', classifier3)], voting ='soft')\n",
    "\n",
    "#params for combination of all 3's best params\n",
    "params = {'logisticregression__penalty' : ['l2'],\n",
    "              'logisticregression__C' : [10],\n",
    "              'logisticregression__solver' : ['liblinear'],\n",
    "              'knn__n_neighbors': [5],\n",
    "              'knn__leaf_size': [10],\n",
    "              'svc__C': [1],\n",
    "              'svc__gamma': [1]\n",
    "             }\n",
    "#combine voting classifier with gridsearch\n",
    "#Gridsearch takes in param_grid, and estimator.\n",
    "gridmerge = GridSearchCV(voteclassifier, param_grid=params, cv =5, scoring = 'roc_auc')\n",
    "gridmerge = gridmerge.fit(X_train, y_train)\n",
    "#on the testing data\n",
    "y_testpred = gridmerge.predict_proba(X_test)\n",
    "#on the training data\n",
    "y_trainpred = gridmerge.predict_proba(X_train)\n",
    "\n",
    "# summarize and present ROC score\n",
    "#roc takes in y_true and y_score\n",
    "COMBINEAUCtest = roc_auc_score(y_test, y_testpred[:,1])\n",
    "COMBINEAUCtrain = roc_auc_score(y_train, y_trainpred[:,1])\n",
    "print('Combine AUC value from test set: ', (COMBINEAUCtest))\n",
    "print('Combine AUC value from train set: ', (COMBINEAUCtrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT ON PERFORMANCE OF ENSEMBLE MODEL\n",
    "\n",
    "Supposedly takes a very very long time as you are putting multiple classifiers into gridsearch. Test Set has improved again to be almost equivalent to what q 3 had. Although there is slight differences being that the one outputted here is 0.0001 of a difference. Which is very insignificant. Training set is still 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
